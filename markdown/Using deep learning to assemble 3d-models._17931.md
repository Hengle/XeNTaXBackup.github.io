## Post #1
- Username: falconcool
- Rank: veteran
- Number of posts: 105
- Joined date: Tue Jun 16, 2009 11:41 am
- Post datetime: 2018-04-06T04:48:11+00:00
- Post Title: Using deep learning to assemble 3d-models.

It's a thinking if we can do this by feeding countless game raw model data and see if it will assemble the model correctly?Since we still have lots of game models are still working in progress like ps2 dirge of ceberus is good example.If anyone familiar with deep learning wanna try it?
## Post #2
- Username: miguelgamendes
- Rank: ultra-n00b
- Number of posts: 1
- Joined date: Tue May 15, 2018 6:15 pm
- Post datetime: 2018-05-15T10:22:29+00:00
- Post Title: Using deep learning to assemble 3d-models.

I think what you want to achieve is possible, but I'm not sure it will have the effect you're looking for.

A deep learning method like, even using raw model data and finished assembled models as training data may teach an AI to build those assembled models from what it sees in the raw data, but if my experience serves me correctly, it will never output an EXACT translation of the raw data.

(it can possibly happen if you feed it data that was present in the original training dataset, but that kinda defeats the point, haha)
## Post #3
- Username: longpinkytoes
- Rank: ultra-n00b
- Number of posts: 6
- Joined date: Tue Feb 27, 2018 2:19 am
- Post datetime: 2018-08-02T00:47:46+00:00
- Post Title: Using deep learning to assemble 3d-models.

deep learning might be overkill for what you are trying to do.
with control of the camera you could attempt to photo-scan the models
but even if the player gets railroaded, programs like Nuke can track video,
and generate point clouds, and create geometry, and texture it with the video

have done this in Nuke, suspect it is possible in Blender too...
